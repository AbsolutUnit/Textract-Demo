{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Textract Conversion.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOLqgGg7GtbiqnZY6vgUtNU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AbsolutUnit/Textract-Pipeline/blob/main/Textract_Conversion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36ukM6Ng-NAO"
      },
      "source": [
        "# Preliminary Pruning and Organization\n",
        "Setting up the format of the data, as well as how it'll be processed before running AWS's textract.\n",
        "\n",
        "We'll be importing boto3, which gives us access to AWS API's and tools."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqizGmNZlM3V",
        "outputId": "16c756b6-667e-4314-dcec-75096868bdf7"
      },
      "source": [
        "!pip install boto3\n",
        "!pip install awscli"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (1.17.112)\n",
            "Requirement already satisfied: botocore<1.21.0,>=1.20.112 in /usr/local/lib/python3.7/dist-packages (from boto3) (1.20.112)\n",
            "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from boto3) (0.4.2)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3) (0.10.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.112->boto3) (1.26.6)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.21.0,>=1.20.112->boto3) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.112->boto3) (1.15.0)\n",
            "Requirement already satisfied: awscli in /usr/local/lib/python3.7/dist-packages (1.19.112)\n",
            "Requirement already satisfied: botocore==1.20.112 in /usr/local/lib/python3.7/dist-packages (from awscli) (1.20.112)\n",
            "Requirement already satisfied: s3transfer<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from awscli) (0.4.2)\n",
            "Requirement already satisfied: rsa<4.8,>=3.1.2; python_version > \"2.7\" in /usr/local/lib/python3.7/dist-packages (from awscli) (4.7.2)\n",
            "Requirement already satisfied: colorama<0.4.4,>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from awscli) (0.4.3)\n",
            "Requirement already satisfied: PyYAML<5.5,>=3.10 in /usr/local/lib/python3.7/dist-packages (from awscli) (3.13)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.7/dist-packages (from awscli) (0.15.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore==1.20.112->awscli) (1.26.6)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore==1.20.112->awscli) (2.8.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from botocore==1.20.112->awscli) (0.10.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<4.8,>=3.1.2; python_version > \"2.7\"->awscli) (0.4.8)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.20.112->awscli) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvJj8UJ3o9T6",
        "outputId": "880cf56c-dad1-4530-ae1a-aa572ec391a9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pqE_E617D9P"
      },
      "source": [
        "import os\n",
        "import boto3\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from botocore import exceptions as ex"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0mJEVDhmDZb",
        "outputId": "6909c909-d739-4a17-ca25-35ad6819340f"
      },
      "source": [
        "!export AWS_SHARED_CREDENTIALS_FILE=/content/drive/My\\ Drive/config/awscli.ini\n",
        "path = \"/content/drive/My Drive/config/awscli.ini\"\n",
        "os.environ['AWS_SHARED_CREDENTIALS_FILE'] = path\n",
        "print(os.environ['AWS_SHARED_CREDENTIALS_FILE'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/config/awscli.ini\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyr3ZG7iogPq",
        "outputId": "7bd98e43-e584-4bff-ea85-c5175caa4e94"
      },
      "source": [
        "!aws s3 ls s3:// --recursive --human-readable --summarize"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-14 19:36:35 bucketofpdfs\n",
            "2021-07-14 20:37:35 outputjsonroseai\n",
            "\n",
            "Total Objects: 0\n",
            "   Total Size: 0 Bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YUSUPg3i55g"
      },
      "source": [
        "Here we can initialize the global variables, like the bucket name and other flags to keep track of during the code execution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n92Cp0I4iklg"
      },
      "source": [
        "input_bucket_name = \"bucketofpdfs\"          # Bucket created earlier under anbarua@cs.stonybrook.edu\n",
        "json_bucket_name = \"outputjsonroseai\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYTHaQlPlW0d"
      },
      "source": [
        "Skeleton code for a function that takes the files and uploads to a bucket. This bucket currently acts as a repository of PDF files ordered by date added and labelled by file name.\n",
        "\n",
        "**To do:** Filter out or deal with invalid file types, or corrupted files/large files that can't be segmented like below. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iv72OPDPzWtE"
      },
      "source": [
        "def pdf_up(doc_name):\n",
        "  s3 = boto3.client('s3')\n",
        "  try:\n",
        "    retval = s3.upload_file(doc_name, input_bucket_name, doc_name)\n",
        "  except ex.ClientError as i:\n",
        "    print(\"Error: \", i)\n",
        "    return False\n",
        "  return True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a29KmZOI23CP"
      },
      "source": [
        "This method, parse_file, chooses a specific file within the bucket to begin the Textract document text detection and extraction from. This returns the job ID, since it runs concurrent to the code via a client."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmJ6NCjUkfhA"
      },
      "source": [
        "def parse_file(bucket_name, doc_name):\n",
        "  client = boto3.client('textract')\n",
        "  retval = client.start_document_text_detection(\n",
        "      DocumentLocation = {'S3Object' : {'Bucket': bucket_name, 'Name' : doc_name}})\n",
        "  return retval[\"JobID\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjJd9rZl5bhC"
      },
      "source": [
        "Skeleton code for main, allowing the entire py file to be easily run from CLI. An idea would be to have flags like -u or -c for upload or conversion. The bucket handling is all within the file, but an example execution could be:\n",
        "\n",
        "python3 Textract-Conversion -u A.pdf B.pdf C.pdf\n",
        "\n",
        "python3 Textract-Conversion -c A B C\n",
        "\n",
        "or even the following\n",
        "\n",
        "python3 Textract-Conversion -u A.pdf B.pdf C.pdf -c"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oToK2I2N5O9m"
      },
      "source": [
        "def main():\n",
        "  # Take in parameters for easier scripting like -u for upload, -c to convert\n",
        "  # pdf upload all valid file names if indicated to upload\n",
        "  # Run compound method which includes parse and wait for JobID completion and add json to second bucket\n",
        "  # return True # after all processes complete\n",
        "  return False\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}